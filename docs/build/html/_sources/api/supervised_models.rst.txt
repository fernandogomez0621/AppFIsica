supervised_models
=================

.. automodule:: src.supervised_models
   :members:
   :undoc-members:
   :show-inheritance:

Descripci贸n General
-------------------

M贸dulo de entrenamiento y evaluaci贸n de m煤ltiples modelos de clasificaci贸n de riesgo crediticio con integraci贸n de caracter铆sticas RBM y optimizaci贸n de hiperpar谩metros.

Clases Principales
------------------

SupervisedModelTrainer
^^^^^^^^^^^^^^^^^^^^^^

.. autoclass:: src.supervised_models.SupervisedModelTrainer
   :members:
   :undoc-members:
   :show-inheritance:
   
   **Descripci贸n:**
   
   Entrenador de modelos supervisados con soporte para m煤ltiples algoritmos y optimizaci贸n autom谩tica.
   
   **Atributos:**
   
   * ``models``: Diccionario de modelos entrenados
   * ``results``: Resultados de evaluaci贸n
   * ``X_train, X_test, X_holdout``: Conjuntos de datos
   * ``y_train, y_test, y_holdout``: Variables objetivo
   * ``feature_names``: Nombres de caracter铆sticas
   * ``label_encoder``: Codificador de etiquetas
   * ``scaler``: Escalador de caracter铆sticas
   * ``model_configs``: Configuraciones de modelos
   
   **Modelos soportados:**
   
   1. **Logistic Regression:** Modelo lineal probabil铆stico
   2. **Random Forest:** Ensemble de 谩rboles de decisi贸n
   3. **XGBoost:** Gradient boosting optimizado
   4. **LightGBM:** Gradient boosting eficiente
   5. **SVM:** Support Vector Machine
   6. **MLP:** Multi-Layer Perceptron (red neuronal)
   
   **Ejemplo de uso:**
   
   .. code-block:: python
   
      from src.supervised_models import SupervisedModelTrainer
      import pandas as pd
      
      # Cargar datos
      df = pd.read_csv("datos_con_caracteristicas.csv")
      
      # Crear entrenador
      trainer = SupervisedModelTrainer()
      
      # Preparar datos
      trainer.prepare_data(df, target_col='nivel_riesgo')
      
      # Entrenar modelo
      results = trainer.train_model('xgboost', use_grid_search=True)
      
      print(f"Accuracy: {results['metrics']['accuracy']:.4f}")
      print(f"F1-Score: {results['metrics']['f1_weighted']:.4f}")

M茅todos de Preparaci贸n
----------------------

prepare_data
^^^^^^^^^^^^

.. automethod:: src.supervised_models.SupervisedModelTrainer.prepare_data
   :noindex:

Prepara datos para entrenamiento con divisi贸n estratificada.

**Parameters:**
   * ``df`` (DataFrame): DataFrame con datos
   * ``target_col`` (str): Variable objetivo (default: 'nivel_riesgo')
   * ``test_size`` (float): Proporci贸n para testing (default: 0.2)
   * ``holdout_size`` (float): Proporci贸n para holdout (default: 0.1)

**Returns:**
   True si exitoso

**Divisi贸n de datos:**
   * 70% Entrenamiento (con validaci贸n cruzada 5-fold)
   * 20% Testing (evaluaci贸n final)
   * 10% Holdout (simulaci贸n de producci贸n)

**Ejemplo:**

.. code-block:: python

   success = trainer.prepare_data(
       df,
       target_col='nivel_riesgo',
       test_size=0.2,
       holdout_size=0.1
   )
   
   if success:
       print(f"Train: {trainer.X_train.shape}")
       print(f"Test: {trainer.X_test.shape}")
       print(f"Holdout: {trainer.X_holdout.shape}")
       print(f"Caracter铆sticas: {len(trainer.feature_names)}")

M茅todos de Entrenamiento
-------------------------

train_model
^^^^^^^^^^^

.. automethod:: src.supervised_models.SupervisedModelTrainer.train_model
   :noindex:

Entrena un modelo espec铆fico con optimizaci贸n opcional.

**Parameters:**
   * ``model_key`` (str): Clave del modelo ('logistic', 'random_forest', 'xgboost', etc.)
   * ``use_grid_search`` (bool): Si usar b煤squeda de hiperpar谩metros (default: True)

**Returns:**
   Diccionario con resultados del entrenamiento

**Proceso:**

1. Cargar configuraci贸n del modelo
2. GridSearchCV si use_grid_search=True
3. Entrenar con mejores par谩metros
4. Calcular m茅tricas completas
5. Guardar modelo y m茅tricas

**Ejemplo:**

.. code-block:: python

   # Entrenar con optimizaci贸n
   results = trainer.train_model('xgboost', use_grid_search=True)
   
   print(f"Mejores par谩metros: {results['best_params']}")
   print(f"Accuracy: {results['metrics']['accuracy']:.4f}")
   print(f"F1-Score: {results['metrics']['f1_weighted']:.4f}")
   print(f"ROC-AUC: {results['metrics']['roc_auc']:.4f}")

train_all_models
^^^^^^^^^^^^^^^^

.. automethod:: src.supervised_models.SupervisedModelTrainer.train_all_models
   :noindex:

Entrena todos los modelos seleccionados.

**Parameters:**
   * ``selected_models`` (List[str]): Lista de modelos a entrenar
   * ``use_grid_search`` (bool): Si usar optimizaci贸n (default: True)

**Returns:**
   Diccionario con resultados de todos los modelos

**Ejemplo:**

.. code-block:: python

   # Entrenar m煤ltiples modelos
   models_to_train = ['logistic', 'random_forest', 'xgboost', 'lightgbm']
   
   all_results = trainer.train_all_models(
       selected_models=models_to_train,
       use_grid_search=True
   )
   
   # Comparar resultados
   for model_key, results in all_results.items():
       print(f"{model_key}:")
       print(f"  Accuracy: {results['metrics']['accuracy']:.4f}")
       print(f"  F1-Score: {results['metrics']['f1_weighted']:.4f}")

M茅todos de Evaluaci贸n
----------------------

_calculate_metrics
^^^^^^^^^^^^^^^^^^

Calcula m茅tricas de evaluaci贸n completas.

**M茅tricas calculadas:**

* **Accuracy:** Precisi贸n global
* **Precision:** Macro y weighted
* **Recall:** Macro y weighted
* **F1-Score:** Macro y weighted
* **Cohen's Kappa:** Acuerdo ajustado por azar
* **Matthews Correlation:** Correlaci贸n de Matthews
* **ROC-AUC:** rea bajo curva ROC
* **Confusion Matrix:** Matriz de confusi贸n
* **Classification Report:** Reporte detallado por clase

**Ejemplo:**

.. code-block:: python

   from sklearn.metrics import classification_report
   
   # Las m茅tricas se calculan autom谩ticamente
   metrics = results['metrics']
   
   print(f"Accuracy: {metrics['accuracy']:.4f}")
   print(f"Precision (weighted): {metrics['precision_weighted']:.4f}")
   print(f"Recall (weighted): {metrics['recall_weighted']:.4f}")
   print(f"F1-Score (weighted): {metrics['f1_weighted']:.4f}")
   print(f"Cohen's Kappa: {metrics['cohen_kappa']:.4f}")
   print(f"ROC-AUC: {metrics['roc_auc']:.4f}")
   
   # Matriz de confusi贸n
   print("\nMatriz de Confusi贸n:")
   print(metrics['confusion_matrix'])
   
   # Reporte por clase
   print("\nReporte de Clasificaci贸n:")
   for class_name, class_metrics in metrics['classification_report'].items():
       if isinstance(class_metrics, dict):
           print(f"{class_name}: {class_metrics}")

M茅todos de Visualizaci贸n
-------------------------

create_comparison_visualizations
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. automethod:: src.supervised_models.SupervisedModelTrainer.create_comparison_visualizations
   :noindex:

Crea visualizaciones comparativas de m煤ltiples modelos.

**Parameters:**
   * ``results`` (Dict): Resultados de m煤ltiples modelos

**Returns:**
   Diccionario con figuras de Plotly

**Visualizaciones:**
   * **model_comparison:** Barras comparativas de m茅tricas
   * **roc_curves:** Curvas ROC superpuestas

create_confusion_matrix_plot
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. automethod:: src.supervised_models.SupervisedModelTrainer.create_confusion_matrix_plot
   :noindex:

Crea visualizaci贸n de matriz de confusi贸n.

**Parameters:**
   * ``model_key`` (str): Clave del modelo
   * ``results`` (Dict): Resultados del modelo

**Returns:**
   Figura de Plotly con heatmap

Funciones de Renderizado
-------------------------

render_supervised_models
^^^^^^^^^^^^^^^^^^^^^^^^^

.. autofunction:: src.supervised_models.render_supervised_models

Renderiza el m贸dulo completo de modelos supervisados en Streamlit.

render_supervised_models_module
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. autofunction:: src.supervised_models.render_supervised_models_module

Funci贸n principal para renderizar el m贸dulo.

Configuraci贸n de Modelos
-------------------------

Logistic Regression
^^^^^^^^^^^^^^^^^^^

**Hiperpar谩metros optimizados:**
   * C: [0.1, 1.0, 10.0]
   * penalty: ['l1', 'l2']
   * solver: ['liblinear']

Random Forest
^^^^^^^^^^^^^

**Hiperpar谩metros optimizados:**
   * n_estimators: [100, 200]
   * max_depth: [10, 20, None]
   * min_samples_split: [2, 5]

XGBoost
^^^^^^^

**Hiperpar谩metros optimizados:**
   * n_estimators: [100, 200]
   * max_depth: [3, 6]
   * learning_rate: [0.01, 0.1]

LightGBM
^^^^^^^^

**Hiperpar谩metros optimizados:**
   * n_estimators: [100, 200]
   * max_depth: [3, 6]
   * learning_rate: [0.01, 0.1]

SVM
^^^

**Hiperpar谩metros optimizados:**
   * C: [0.1, 1.0, 10.0]
   * kernel: ['rbf', 'linear']

MLP
^^^

**Hiperpar谩metros optimizados:**
   * hidden_layer_sizes: [(100,), (100, 50)]
   * alpha: [0.001, 0.01]
   * learning_rate: ['constant', 'adaptive']

Ejemplo Completo
----------------

.. code-block:: python

   from src.supervised_models import SupervisedModelTrainer
   import pandas as pd
   
   # Cargar datos con caracter铆sticas RBM
   df = pd.read_csv("datos_con_rbm.csv")
   
   # Crear entrenador
   trainer = SupervisedModelTrainer()
   
   # Preparar datos
   trainer.prepare_data(df, target_col='nivel_riesgo')
   
   # Entrenar m煤ltiples modelos
   models = ['logistic', 'random_forest', 'xgboost', 'lightgbm']
   all_results = trainer.train_all_models(models, use_grid_search=True)
   
   # Comparar modelos
   print("Comparaci贸n de Modelos:")
   print("-" * 60)
   
   for model_key, results in all_results.items():
       metrics = results['metrics']
       print(f"\n{trainer.model_configs[model_key]['name']}:")
       print(f"  Accuracy:  {metrics['accuracy']:.4f}")
       print(f"  F1-Score:  {metrics['f1_weighted']:.4f}")
       print(f"  Precision: {metrics['precision_weighted']:.4f}")
       print(f"  Recall:    {metrics['recall_weighted']:.4f}")
       print(f"  ROC-AUC:   {metrics.get('roc_auc', 0):.4f}")
       print(f"  Kappa:     {metrics['cohen_kappa']:.4f}")
   
   # Crear visualizaciones comparativas
   comparison_figs = trainer.create_comparison_visualizations(all_results)
   comparison_figs['model_comparison'].show()
   comparison_figs['roc_curves'].show()
   
   # Analizar mejor modelo
   best_model_key = max(
       all_results.keys(),
       key=lambda k: all_results[k]['metrics']['f1_weighted']
   )
   
   print(f"\n Mejor modelo: {trainer.model_configs[best_model_key]['name']}")
   
   best_results = all_results[best_model_key]
   
   # Matriz de confusi贸n
   fig_cm = trainer.create_confusion_matrix_plot(best_model_key, best_results)
   fig_cm.show()
   
   # Importancia de caracter铆sticas (si disponible)
   if hasattr(best_results['model'], 'feature_importances_'):
       importances = best_results['model'].feature_importances_
       feature_importance_df = pd.DataFrame({
           'Feature': trainer.feature_names,
           'Importance': importances
       }).sort_values('Importance', ascending=False)
       
       print("\nTop 10 Caracter铆sticas:")
       print(feature_importance_df.head(10))

Interpretaci贸n de M茅tricas
---------------------------

Accuracy
^^^^^^^^

Proporci贸n de predicciones correctas.

.. math::

   \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}

* **> 0.90:** Excelente
* **0.80-0.90:** Muy bueno
* **0.70-0.80:** Bueno
* **< 0.70:** Revisar modelo

Precision
^^^^^^^^^

Proporci贸n de predicciones positivas correctas.

.. math::

   \text{Precision} = \frac{TP}{TP + FP}

Recall (Sensibilidad)
^^^^^^^^^^^^^^^^^^^^^

Proporci贸n de positivos reales detectados.

.. math::

   \text{Recall} = \frac{TP}{TP + FN}

F1-Score
^^^^^^^^

Media arm贸nica de precision y recall.

.. math::

   F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}

Cohen's Kappa
^^^^^^^^^^^^^

Acuerdo entre predicciones y realidad, ajustado por azar.

* **< 0:** Peor que azar
* **0-0.20:** Acuerdo leve
* **0.21-0.40:** Acuerdo justo
* **0.41-0.60:** Acuerdo moderado
* **0.61-0.80:** Acuerdo sustancial
* **0.81-1.00:** Acuerdo casi perfecto

ROC-AUC
^^^^^^^

rea bajo la curva ROC (Receiver Operating Characteristic).

* **0.90-1.00:** Excelente
* **0.80-0.90:** Muy bueno
* **0.70-0.80:** Bueno
* **0.60-0.70:** Pobre
* **0.50-0.60:** Falla

Funciones de Renderizado
-------------------------

render_supervised_models
^^^^^^^^^^^^^^^^^^^^^^^^^

.. autofunction:: src.supervised_models.render_supervised_models

Renderiza el m贸dulo completo de modelos supervisados en Streamlit.

**Funcionalidades:**
   * Selecci贸n de dataset (original, con caracter铆sticas, con RBM)
   * Selecci贸n de modelos a entrenar
   * Optimizaci贸n de hiperpar谩metros
   * Entrenamiento con barra de progreso
   * Comparaci贸n de modelos
   * An谩lisis detallado por modelo
   * Visualizaci贸n de importancia de caracter铆sticas

render_supervised_models_module
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. autofunction:: src.supervised_models.render_supervised_models_module

Funci贸n principal para renderizar el m贸dulo.

Ejemplo de Optimizaci贸n de Hiperpar谩metros
-------------------------------------------

.. code-block:: python

   from src.supervised_models import SupervisedModelTrainer
   from sklearn.model_selection import GridSearchCV
   
   # Crear entrenador
   trainer = SupervisedModelTrainer()
   trainer.prepare_data(df)
   
   # Configuraci贸n personalizada para XGBoost
   custom_params = {
       'n_estimators': [50, 100, 200, 300],
       'max_depth': [3, 4, 5, 6, 7],
       'learning_rate': [0.01, 0.05, 0.1, 0.2],
       'subsample': [0.8, 0.9, 1.0],
       'colsample_bytree': [0.8, 0.9, 1.0]
   }
   
   # Actualizar configuraci贸n
   trainer.model_configs['xgboost']['params'] = custom_params
   
   # Entrenar con b煤squeda exhaustiva
   results = trainer.train_model('xgboost', use_grid_search=True)
   
   print(f"Mejores hiperpar谩metros encontrados:")
   for param, value in results['best_params'].items():
       print(f"  {param}: {value}")

Ejemplo de Validaci贸n Cruzada
------------------------------

.. code-block:: python

   from sklearn.model_selection import cross_val_score
   
   # Entrenar modelo
   results = trainer.train_model('random_forest')
   model = results['model']
   
   # Validaci贸n cruzada 5-fold
   cv_scores = cross_val_score(
       model,
       trainer.X_train_scaled,
       trainer.y_train,
       cv=5,
       scoring='f1_weighted'
   )
   
   print(f"F1-Scores por fold: {cv_scores}")
   print(f"Media: {cv_scores.mean():.4f}")
   print(f"Desv. Est谩ndar: {cv_scores.std():.4f}")

Ejemplo de An谩lisis de Errores
-------------------------------

.. code-block:: python

   import numpy as np
   
   # Obtener predicciones
   y_pred = results['predictions']['y_test_pred']
   y_true = trainer.y_test
   
   # Identificar errores
   errors_mask = y_pred != y_true
   errors_indices = np.where(errors_mask)[0]
   
   print(f"Total de errores: {errors_mask.sum()}")
   print(f"Tasa de error: {errors_mask.sum() / len(y_true):.2%}")
   
   # Analizar errores por clase
   for class_idx, class_name in enumerate(trainer.label_encoder.classes_):
       class_mask = y_true == class_idx
       class_errors = errors_mask[class_mask].sum()
       class_total = class_mask.sum()
       
       print(f"\nClase '{class_name}':")
       print(f"  Total: {class_total}")
       print(f"  Errores: {class_errors}")
       print(f"  Tasa de error: {class_errors/class_total:.2%}")
   
   # Ver casos mal clasificados
   X_test_df = pd.DataFrame(
       trainer.X_test,
       columns=trainer.feature_names
   )
   
   errors_df = X_test_df.iloc[errors_indices].copy()
   errors_df['true_class'] = trainer.label_encoder.inverse_transform(y_true[errors_indices])
   errors_df['predicted_class'] = trainer.label_encoder.inverse_transform(y_pred[errors_indices])
   
   print("\nPrimeros 5 casos mal clasificados:")
   print(errors_df[['true_class', 'predicted_class']].head())

Guardado de Modelos
-------------------

Los modelos se guardan autom谩ticamente en:

* **Modelo:** ``models/supervised/{model_key}_model.pkl``
* **M茅tricas:** ``models/supervised/{model_key}_metrics.json``

**Contenido del archivo de modelo:**

.. code-block:: python

   {
       'model': trained_model,
       'scaler': StandardScaler,
       'label_encoder': LabelEncoder,
       'feature_names': list,
       'best_params': dict,
       'metrics': dict,
       'timestamp': str
   }

Ver tambi茅n
-----------

* :doc:`feature_engineering` - Ingenier铆a de caracter铆sticas
* :doc:`rbm_model` - Caracter铆sticas RBM
* :doc:`prediction` - Sistema de predicci贸n
* :doc:`retraining` - Reentrenamiento de modelos